{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install librosa\n",
    "%pip install torchaudio\n",
    "%pip install torchvision\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kareem/projects/videoxt/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'الهردة جمعة هكلمك في اهم خمس كنوات بودكاست تتفرج عليهم او تسمعهم على اليوتيوب والبودكاست جمعة بجد مهمة جدا للفترة الاخيرة دي وهي فيدة جدا في حياتك وفعلا حياتك هتتغير تماما وابل ما بدا الفيديو متتصل على الناب وتعمل لايك وتنزل تشترك في الكنوان دلوقت حالا انزل تشترك في الكنوان'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import transformers\n",
    "\n",
    "model = transformers.WhisperForConditionalGeneration.from_pretrained(\"./models/whisper_large_v2_arabic_aug\")\n",
    "processor = transformers.WhisperProcessor.from_pretrained(\"./models/whisper_large_v2_arabic_aug\")\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"arabic\", task=\"transcribe\")\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def prepare_features(audio_path):\n",
    "    waveform, sample_rate = librosa.load(audio_path, sr=None)\n",
    "    return (waveform, sample_rate)\n",
    "\n",
    "# all_chunks = []\n",
    "# for file in os.listdir(\"./downloads/segments\"):\n",
    "#     input_features, input_samplerate = prepare_features(f\"./downloads/segments/{file}\")\n",
    "#     inputs = processor.feature_extractor(input_features, return_tensors=\"pt\", sampling_rate=input_samplerate).input_features # .to(device)\n",
    "#     predicted_ids = model.generate(inputs, max_length=480_000, forced_decoder_ids=forced_decoder_ids)\n",
    "#     result = processor.tokenizer.batch_decode(predicted_ids, skip_special_tokens=True, normalize=True)[0]\n",
    "#     print(result)\n",
    "#     all_chunks.extend([result])\n",
    "\n",
    "# all_chunks.reverse()\n",
    "# print(all_chunks)\n",
    "\n",
    "\n",
    "input_features, input_samplerate = prepare_features(\"./downloads/segments/0.wav\")\n",
    "inputs = processor.feature_extractor(input_features, return_tensors=\"pt\", sampling_rate=input_samplerate).input_features #.to(device)\n",
    "predicted_ids = model.generate(inputs, forced_decoder_ids=forced_decoder_ids)\n",
    "processor.tokenizer.batch_decode(predicted_ids, skip_special_tokens=True, normalize=True)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
